{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c780bebd-5768-4f31-9445-c6287bca8d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/__init__.py\", line 8, in <module>\n",
      "    from .runtime import (\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/runtime/__init__.py\", line 1, in <module>\n",
      "    from .autotuner import (Autotuner, Config, Heuristics, autotune, heuristics)\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 9, in <module>\n",
      "    from ..testing import do_bench, do_bench_cudagraph\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/testing.py\", line 7, in <module>\n",
      "    from . import language as tl\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/language/__init__.py\", line 4, in <module>\n",
      "    from . import math\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/language/math.py\", line 1, in <module>\n",
      "    from . import core\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/language/core.py\", line 10, in <module>\n",
      "    from ..runtime.jit import jit\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/runtime/jit.py\", line 12, in <module>\n",
      "    from ..runtime.driver import driver\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/runtime/driver.py\", line 1, in <module>\n",
      "    from ..backends import backends\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/backends/__init__.py\", line 50, in <module>\n",
      "    backends = _discover_backends()\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/backends/__init__.py\", line 44, in _discover_backends\n",
      "    driver = _load_module(name, os.path.join(root, name, 'driver.py'))\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/backends/__init__.py\", line 12, in _load_module\n",
      "    spec.loader.exec_module(module)\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/backends/amd/driver.py\", line 7, in <module>\n",
      "    from triton.runtime.build import _build\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/triton/runtime/build.py\", line 8, in <module>\n",
      "    import setuptools\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/setuptools/__init__.py\", line 18, in <module>\n",
      "    from setuptools.dist import Distribution\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/setuptools/dist.py\", line 39, in <module>\n",
      "    from setuptools.config import parse_configuration\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/setuptools/config/__init__.py\", line 9, in <module>\n",
      "    from . import setupcfg\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/setuptools/config/setupcfg.py\", line 27, in <module>\n",
      "    from .._path import StrPath\n",
      "  File \"/home/galkesten/miniconda3/envs/sana/lib/python3.10/site-packages/setuptools/_path.py\", line 8, in <module>\n",
      "    from more_itertools import unique_everseen\n",
      "ModuleNotFoundError: No module named 'more_itertools'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6226be4ff9b4e8684103e959cabe4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184500057c714e518b7ff29989a694ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2Model(\n",
       "  (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-25): 26 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import SanaPipeline\n",
    "\n",
    "pipe = SanaPipeline.from_pretrained(\n",
    "    \"Efficient-Large-Model/Sana_1600M_1024px_diffusers\",\n",
    "    #\"Efficient-Large-Model/Sana_600M_1024px_diffusers\",\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "pipe.vae.to(torch.bfloat16)\n",
    "pipe.text_encoder.to(torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb10895-d40c-4cbb-bb2f-fda645a693e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SanaPipeline {\n",
       "  \"_class_name\": \"SanaPipeline\",\n",
       "  \"_diffusers_version\": \"0.34.0.dev0\",\n",
       "  \"_name_or_path\": \"Efficient-Large-Model/Sana_1600M_1024px_diffusers\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DPMSolverMultistepScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"Gemma2Model\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"GemmaTokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"SanaTransformer2DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderDC\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4919cfa1-cf2f-4103-be48-dba88e9ce06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipe.transformer.transformer_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad963df7-cc86-472c-8d4a-b7c14a5a7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34314cf-9ec0-40e9-8b50-c838d94decc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating baseline image (no ablation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6192832b58043e790c8d7c3192080f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero ablating FFN in block 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955656c194f540049f9204a94881e766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 0: 2.99 seconds\n",
      "Zero ablating FFN in block 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440226bc73894c058998de78822857e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 1: 2.99 seconds\n",
      "Zero ablating FFN in block 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ae6fcb4fea452cab35dc87714f1b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 2: 2.99 seconds\n",
      "Zero ablating FFN in block 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3dbc7b332b44e39ba100730c1d4b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 3: 3.02 seconds\n",
      "Zero ablating FFN in block 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7caa890a544b70b7114e8cace74c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 4: 3.01 seconds\n",
      "Zero ablating FFN in block 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43b4c9187cc41cab2cc9c02ddffa7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 5: 3.00 seconds\n",
      "Zero ablating FFN in block 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d10321627144ae486cffafba291defb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 6: 3.00 seconds\n",
      "Zero ablating FFN in block 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f2bdef60114e6b8acd093382ddabf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 7: 3.00 seconds\n",
      "Zero ablating FFN in block 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdee3fab58349aa9e0acdd1b9ba8002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 8: 3.00 seconds\n",
      "Zero ablating FFN in block 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c97a78e92d94068a1329fee67ec990b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 9: 3.01 seconds\n",
      "Zero ablating FFN in block 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2bbee0728b47d78b37851c79bbe680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 10: 3.01 seconds\n",
      "Zero ablating FFN in block 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775a37bbf52d421c82916c1906a830e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 11: 3.01 seconds\n",
      "Zero ablating FFN in block 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ee82fa210a4fff8f0e5486bf104612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 12: 3.01 seconds\n",
      "Zero ablating FFN in block 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dce00c950342c1b89d5e8cebd3dc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 13: 3.01 seconds\n",
      "Zero ablating FFN in block 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626bb7c08d4543d0be5a03d518cc1c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 14: 3.01 seconds\n",
      "Zero ablating FFN in block 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e790bf7b5a414beeac0f63150ccdffa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 15: 3.01 seconds\n",
      "Zero ablating FFN in block 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9275b51884b4150982bc43b50097a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 16: 3.01 seconds\n",
      "Zero ablating FFN in block 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2876f8cf1714a5d9a8332fc712e4e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 17: 3.01 seconds\n",
      "Zero ablating FFN in block 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6aac0d6cdf4f23bc44d0051a2e489b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 18: 3.01 seconds\n",
      "Zero ablating FFN in block 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d007430726a14647a1f15a44f3f961e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time for block 19: 3.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "\n",
    "def zero_ablation_hook(module, input, output):\n",
    "    return torch.zeros_like(output)\n",
    "\n",
    "def mean_ablation_hook(module, input, output):\n",
    "    return output.mean(dim=1, keepdim=True).expand_as(output)\n",
    "\n",
    "# === Create output directory ===\n",
    "os.makedirs(\"ablated_outputs\", exist_ok=True)\n",
    "\n",
    "# === Define prompt ===\n",
    "prompt = \"a photo of a cow right of a laptop\"\n",
    "\n",
    "# === Generate and save baseline (no ablation) ===\n",
    "print(\"Generating baseline image (no ablation)\")\n",
    "baseline_image = pipe(\n",
    "    prompt=prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=5.0,\n",
    "    num_inference_steps=20,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ")[0]\n",
    "baseline_image[0].save(\"ablated_outputs/baseline_no_ablation.png\")\n",
    "\n",
    "# === Iterate over transformer blocks for zero ablation ===\n",
    "for idx, block in enumerate(pipe.transformer.transformer_blocks):\n",
    "    print(f\"Zero ablating FFN in block {idx}\")\n",
    "\n",
    "    # Register hook\n",
    "    handle = block.ff.register_forward_hook(zero_ablation_hook)\n",
    "\n",
    "    # Measure time\n",
    "    start_time = time.time()\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        guidance_scale=5.0,\n",
    "        num_inference_steps=20,\n",
    "        generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    "    )[0]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Generation time for block {idx}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save image\n",
    "    image[0].save(f\"ablated_outputs/ablated_block{idx}_ffn_zero.png\")\n",
    "\n",
    "    # Remove hook\n",
    "    handle.remove()\n",
    "\n",
    "# # === Optional: Repeat for mean ablation ===\n",
    "# for idx, block in enumerate(pipe.transformer.transformer_blocks):\n",
    "#     print(f\"Mean ablating FFN in block {idx}\")\n",
    "\n",
    "#     # Register hook\n",
    "#     handle = block.ff.register_forward_hook(mean_ablation_hook)\n",
    "\n",
    "#     # Generate image\n",
    "#     image = pipe(\n",
    "#         prompt=prompt,\n",
    "#         height=1024,\n",
    "#         width=1024,\n",
    "#         guidance_scale=5.0,\n",
    "#         num_inference_steps=20,\n",
    "#         generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    "#     )[0]\n",
    "\n",
    "#     # Save image\n",
    "#     image[0].save(f\"ablated_outputs/ablated_block{idx}_ffn_mean.png\")\n",
    "\n",
    "#     # Remove hook\n",
    "#     handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a977f5-07c2-451e-9bd9-7a35fd5919f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating baseline image (no ablation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f0f553dd0e439f91ca8eb9c2ecf138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ablating attn1 in block 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722c0afa6d2148ccb86a487454d31a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc582b790724cbda2dbd75178ceb8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d5baab61134b29a5e4faea9762983e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518d1f843d4b4b0688a708834599f74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8916cbd9a943f7a5f51870619a4f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1320866e8ab841e6b9820437771fc03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d260df61f06344d0a1d2f0d892922dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380e43f572ef46bc92dd3c391a2bf358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b6abe243054e5c949ee7c19343ab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1741d4483a412ca4957c139d0f5657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2600730245bf48e0a21975ae99d82fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ecf021f2f8473a9c2372879179c182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7cdb1f51a24f6bb0bf3c500fff6483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4c9e7d805b4d7e8ff9050ee1e186b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff14bfa72a4480e90706412480babd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6823c9f2e1478bb2328ab1476bff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423e6641f49d452188e439452a08ab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9afc1186bc5441d9799a741dc6c1e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc24ac51e88c42ae9dc7e8faff201755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "Mean ablating attn1 in block 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4870e57372704c06ba7570132651b15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n",
      "torch.Size([2, 1024, 2240])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def zero_ablation_hook(module, input, output):\n",
    "    return torch.zeros_like(output)\n",
    "\n",
    "def mean_ablation_hook(module, input, output):\n",
    "    ret= output.mean(dim=1, keepdim=True).expand_as(output)\n",
    "    print(ret.shape)\n",
    "    return ret\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"ablated_outputs_attn1\", exist_ok=True)\n",
    "\n",
    "# Define prompt\n",
    "prompt = \"a banana at the top of the image and an apple at the bottom\"\n",
    "\n",
    "# === Generate and save baseline image ===\n",
    "print(\"Generating baseline image (no ablation)\")\n",
    "baseline_image = pipe(\n",
    "    prompt=prompt,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    guidance_scale=5.0,\n",
    "    num_inference_steps=20,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ")[0]\n",
    "baseline_image[0].save(\"ablated_outputs_attn1/baseline_no_ablation.png\")\n",
    "\n",
    "# === Iterate over transformer blocks and ablate attn1 ===\n",
    "for idx, block in enumerate(pipe.transformer.transformer_blocks):\n",
    "    print(f\"Mean ablating attn1 in block {idx}\")\n",
    "\n",
    "    # Register hook on attn1\n",
    "    handle = block.attn1.register_forward_hook(mean_ablation_hook)\n",
    "\n",
    "    # Generate image with ablated attn1\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        guidance_scale=5.0,\n",
    "        num_inference_steps=20,\n",
    "        generator=torch.Generator(device=\"cuda\").manual_seed(42),  # fresh generator\n",
    "    )[0]\n",
    "\n",
    "    # Save image\n",
    "    image[0].save(f\"ablated_outputs_attn1/ablated_block{idx}_attn1_mean.png\")\n",
    "\n",
    "    # Remove hook\n",
    "    handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ca34a-7952-4423-8299-29fb644d666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0211fc9-7b6f-4206-8c48-eed16c96e8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981b609-a589-4160-a44c-22b1369fb816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693d9e7-9e35-40bc-b8ba-3346c53f1e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
